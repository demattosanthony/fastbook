{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using full mnist dataset and creating neural net from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import inflect\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) [Path('training/0'),Path('training/1'),Path('training/2'),Path('training/3'),Path('training/4'),Path('training/5'),Path('training/6'),Path('training/7'),Path('training/8'),Path('training/9')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'training').ls().sorted()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looping through training data and storing it in numbers dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = inflect.engine()\n",
    "numbers = {}\n",
    "for i in (path/'training').ls().sorted():\n",
    "    num = str(i)[-1]\n",
    "    for n in num:\n",
    "        val = p.number_to_words(n)\n",
    "        numbers[val] = (path/'training/{}'.format(n)).ls().sorted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_tensors = {}\n",
    "for key, val in numbers.items():\n",
    "    numbers_tensors[key] = [tensor(Image.open(o)) for o in val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6742, 5958)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(numbers_tensors['one']),len(numbers_tensors['two'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABECAYAAAA4E5OyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAADjUlEQVR4nO2cTW8bRQCGn5n1rp1NHKeYhNpJ00iEBoIoh6IeOHBAfEicigSCG4eKA3d+AEfEjV+AxBFOPUIlQIIDUpFaCoFCQ1NUghs7/iiJ15+7w6FEKVO3t86MqnmOa0vv60ezO96d0QqlFJ5DpO0CruGFaHghGl6Ihheikbvfhy/LNx/aKeh89rmYdNyPEA0vRMML0fBCNLwQDS9E477T7gMNXlmmtzqPyklUAIV6n6DeQe13Ud2EbDiCLDXfy3jif/z1+hLvvXuOY1GTlVybty+eJfxyidLWmKk/mgSNJmnnlvFe1k6ZNA/rhW3Ww12ejqZ4fnGL9smUxrMh7ecWYPGolV7WRggKMiXJgFRlfFT9ig+Onufc/hrftNfY/GSN8ob5WvaE3EGGIhYRcXB71CSlPFfiJ610cW6WeSZMeGP2MsOinXznhEghCG3mW8x2Ei9EwwvRcFZIllcEcyVEGBnNdU5IgCAQgnGsoLKAnJk2mu+cEIkkLyRyscfu6UehumA43zFCERCLiFdWr9B6tcf+aslovnNCDpAiQwBMfBT8AHPNxrmPF6LhhWg4K6QcdjlS6jKckchiEZEzc2PurJBK1GGp2GFYFMjSLCKfN5LrrJBTheucWbhItwrjpTLC0B80Z4WcjALeKtYYVkYklSnEdGwk15qQ6Jbis9ZpLg2qtipMxJ6QPcX3teP81q/YqjARa0Jmtof0fijzdeOErQoTsTdCav9Q3kj5s3HEVoWJOHtRtYUXouGFaLgvRIAy2NJpIRLJsaUm9VOSYXXOUKYtlEJkoDLJSKVkZBO/9kSpQbrcZzRrZvnKnpBGi+LPDcKNmPdrL/BFMvlR4WuPXObMUz+SzD/kd7vZ3h7q7x3iuuLCzjKbg8nbH9ajm7xY+oWxmVsZe0JUmpL1+gQDSAYhSWZ2/eVeWNwfokClyLFiNMzRz2wucR9ifZbJd1LUjZjN7vw9L6wmsS4kl6REbUG7H5MqdZeUROVojmcQhvbfWd9BFP10nePbc/y6UmFwYkyeHPKOtZiPb77Ed7+vsnxjbKSPdSFpswXNFlH9MS4MSkzLAQVx+8enCC7tLJLfKhB1ukb6WBdywOOf7vDht++gBCAOh0h1t4fs1KDexMRZ44yQ9Oo1wqvX7jquwIiIA6xfVF3DC9HwQjS8EA0vRMML0RD+ZQj/x48QDS9EwwvR8EI0vBANL0TjX8E5BcMcUxKSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(numbers_tensors['one'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6742, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_numbers = {}\n",
    "for key, val in numbers_tensors.items():\n",
    "    stacked_numbers[key] = torch.stack(numbers_tensors[key]).float()/255\n",
    "stacked_numbers['one'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.37it/s]\n"
     ]
    }
   ],
   "source": [
    "valid_numbers = {}\n",
    "for i in tqdm((path/'testing').ls().sorted()):\n",
    "    num = str(i)[-1]\n",
    "    for n in num:\n",
    "        val = p.number_to_words(n)\n",
    "        valid_numbers[val] = (path/'testing/{}'.format(n)).ls().sorted()\n",
    "        valid_numbers[val] = torch.stack([tensor(Image.open(o)) for o in numbers[val]]).float()/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6742, 28, 28])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_numbers['one'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.cat([val for key, val in stacked_numbers.items()]).view(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0,  ..., 0, 0, 0],\n",
       "        [1, 0, 0,  ..., 0, 0, 0],\n",
       "        [1, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 1],\n",
       "        [0, 0, 0,  ..., 0, 0, 1],\n",
       "        [0, 0, 0,  ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = tensor([[1,0,0,0,0,0,0,0,0,0] for i in range(len(stacked_numbers['zero']))]\n",
    "                + [[0,1,0,0,0,0,0,0,0,0] for i in range(len(stacked_numbers['one']))]\n",
    "                + [[0,0,1,0,0,0,0,0,0,0] for i in range(len(stacked_numbers['two']))]\n",
    "                + [[0,0,0,1,0,0,0,0,0,0] for i in range(len(stacked_numbers['three']))]\n",
    "                + [[0,0,0,0,1,0,0,0,0,0] for i in range(len(stacked_numbers['four']))]\n",
    "                + [[0,0,0,0,0,1,0,0,0,0] for i in range(len(stacked_numbers['five']))]\n",
    "                + [[0,0,0,0,0,0,1,0,0,0] for i in range(len(stacked_numbers['six']))]\n",
    "                + [[0,0,0,0,0,0,0,1,0,0] for i in range(len(stacked_numbers['seven']))]\n",
    "                + [[0,0,0,0,0,0,0,0,1,0] for i in range(len(stacked_numbers['eight']))]\n",
    "                + [[0,0,0,0,0,0,0,0,0,1] for i in range(len(stacked_numbers['nine']))])\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 784]), torch.Size([60000, 10]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = list(zip(train_x,train_y))\n",
    "x,y = dset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x = torch.cat([val for key,val in valid_numbers.items()]).view(-1,28*28)\n",
    "valid_y = tensor([[1,0,0,0,0,0,0,0,0,0] for i in range(len(valid_numbers['zero']))]\n",
    "                + [[0,1,0,0,0,0,0,0,0,0] for i in range(len(valid_numbers['one']))]\n",
    "                + [[0,0,1,0,0,0,0,0,0,0] for i in range(len(valid_numbers['two']))]\n",
    "                + [[0,0,0,1,0,0,0,0,0,0] for i in range(len(valid_numbers['three']))]\n",
    "                + [[0,0,0,0,1,0,0,0,0,0] for i in range(len(valid_numbers['four']))]\n",
    "                + [[0,0,0,0,0,1,0,0,0,0] for i in range(len(valid_numbers['five']))]\n",
    "                + [[0,0,0,0,0,0,1,0,0,0] for i in range(len(valid_numbers['six']))]\n",
    "                + [[0,0,0,0,0,0,0,1,0,0] for i in range(len(valid_numbers['seven']))]\n",
    "                + [[0,0,0,0,0,0,0,0,1,0] for i in range(len(valid_numbers['eight']))]\n",
    "                + [[0,0,0,0,0,0,0,0,0,1] for i in range(len(valid_numbers['nine']))])\n",
    "valid_dset = list(zip(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beginnning to define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = init_params((28*28,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = init_params(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-14.2235,   2.5135,   5.7116,  ...,   9.4554,  -3.3564,  10.3545],\n",
       "        [  0.6765, -11.2653,  -0.3464,  ..., -13.5279,   2.7670,   6.3045],\n",
       "        [-15.3282, -14.3088,  11.1773,  ..., -10.0685,  -3.9030,  16.2079],\n",
       "        ...,\n",
       "        [  7.0098,  -7.7707,   4.1305,  ..., -15.0312,  15.5410,  -2.7895],\n",
       "        [ -5.9912,  -5.6965,  -4.8020,  ...,  -1.0565,   8.5268,   8.8449],\n",
       "        [  0.5527,  -6.1358,  -3.0585,  ..., -15.1684,   6.6871,   0.5494]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linear1(xb): return xb@weights + bias\n",
    "preds = linear1(train_x)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(predictions, targets):\n",
    "    #predictions = predictions.softmax(dim=1)\n",
    "    target = torch.max(targets,1).indices\n",
    "    #print(predictions,target)\n",
    "    return nn.CrossEntropyLoss()(predictions,target)\n",
    "    #loss = -(targets * predictions.log()).sum() / len(predictions)\n",
    "    #return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3588, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_loss(preds,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 784]), torch.Size([256, 10]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(dset, batch_size=256)\n",
    "valid_dl = DataLoader(valid_dset, batch_size=256)\n",
    "xb,yb = first(dl)\n",
    "xb.shape,yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing loss on small batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 784])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = train_x[:4]\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = linear1(batch)\n",
    "#preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-14.2235,   2.5135,   5.7116, -25.6359,  -0.4638,  -1.6191,  -4.8965,\n",
      "           9.4554,  -3.3564,  10.3545],\n",
      "        [  0.6765, -11.2653,  -0.3464, -16.5384,  10.3884,  -0.3390,  -2.4381,\n",
      "         -13.5279,   2.7670,   6.3045],\n",
      "        [-15.3282, -14.3088,  11.1773, -23.3850,  -6.6150,  -3.7608,  -4.0430,\n",
      "         -10.0685,  -3.9030,  16.2079],\n",
      "        [ 20.6653, -24.6875,  13.5886, -17.2491,  15.7998,  -8.4107,   6.7850,\n",
      "          11.9316,  10.1477,   4.8569]], grad_fn=<AddBackward0>) tensor([0, 0, 0, 0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(16.5518, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = mnist_loss(preds,train_y[:4])\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2500)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_accuracy(linear1(batch), train_y[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0851"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_epoch(linear1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining functions to implement model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad(xb,yb, model):\n",
    "    preds = model(xb)\n",
    "    loss = mnist_loss(preds,yb)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, lr, params):\n",
    "    for xb,yb in dl:\n",
    "        calc_grad(xb,yb, model)\n",
    "        for p in params:\n",
    "            p.data -= p.grad*lr\n",
    "            p.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.softmax(dim=1)\n",
    "    predVal, predMax = torch.max(preds.data,1)\n",
    "    tarVal, tarMax = torch.max(yb,1)\n",
    "    correct = predMax == tarMax\n",
    "    return correct.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "params = weights,bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6454 0.6468 0.6484 0.65 0.6514 0.653 0.6541 0.6552 0.6565 0.6576 0.6592 0.6605 0.6619 0.6629 0.6642 0.6655 0.667 0.6682 0.6696 0.6707 0.6717 0.6728 0.6737 0.6751 0.6762 0.6772 0.6784 0.6796 0.6808 0.6821 0.6832 0.6839 0.6851 0.6862 0.6872 0.6882 0.6892 0.6903 0.6912 0.6921 "
     ]
    }
   ],
   "source": [
    "for i in range(40):\n",
    "    train_epoch(linear1, lr, params)\n",
    "    print(validate_epoch(linear1), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
