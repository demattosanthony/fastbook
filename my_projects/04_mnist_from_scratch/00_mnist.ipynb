{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using full mnist dataset and creating neural net from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import inflect\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) [Path('training/0'),Path('training/1'),Path('training/2'),Path('training/3'),Path('training/4'),Path('training/5'),Path('training/6'),Path('training/7'),Path('training/8'),Path('training/9')]"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'training').ls().sorted()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looping through training data and storing it in numbers dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = inflect.engine()\n",
    "numbers = {}\n",
    "for i in (path/'training').ls().sorted():\n",
    "    num = str(i)[-1]\n",
    "    for n in num:\n",
    "        val = p.number_to_words(n)\n",
    "        numbers[val] = (path/'training/{}'.format(n)).ls().sorted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_tensors = {}\n",
    "for key, val in numbers.items():\n",
    "    numbers_tensors[key] = [tensor(Image.open(o)) for o in val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6742, 5958)"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(numbers_tensors['one']),len(numbers_tensors['two'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABECAYAAAA4E5OyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAADjUlEQVR4nO2cTW8bRQCGn5n1rp1NHKeYhNpJ00iEBoIoh6IeOHBAfEicigSCG4eKA3d+AEfEjV+AxBFOPUIlQIIDUpFaCoFCQ1NUghs7/iiJ15+7w6FEKVO3t86MqnmOa0vv60ezO96d0QqlFJ5DpO0CruGFaHghGl6Ihheikbvfhy/LNx/aKeh89rmYdNyPEA0vRMML0fBCNLwQDS9E477T7gMNXlmmtzqPyklUAIV6n6DeQe13Ud2EbDiCLDXfy3jif/z1+hLvvXuOY1GTlVybty+eJfxyidLWmKk/mgSNJmnnlvFe1k6ZNA/rhW3Ww12ejqZ4fnGL9smUxrMh7ecWYPGolV7WRggKMiXJgFRlfFT9ig+Onufc/hrftNfY/GSN8ob5WvaE3EGGIhYRcXB71CSlPFfiJ610cW6WeSZMeGP2MsOinXznhEghCG3mW8x2Ei9EwwvRcFZIllcEcyVEGBnNdU5IgCAQgnGsoLKAnJk2mu+cEIkkLyRyscfu6UehumA43zFCERCLiFdWr9B6tcf+aslovnNCDpAiQwBMfBT8AHPNxrmPF6LhhWg4K6QcdjlS6jKckchiEZEzc2PurJBK1GGp2GFYFMjSLCKfN5LrrJBTheucWbhItwrjpTLC0B80Z4WcjALeKtYYVkYklSnEdGwk15qQ6Jbis9ZpLg2qtipMxJ6QPcX3teP81q/YqjARa0Jmtof0fijzdeOErQoTsTdCav9Q3kj5s3HEVoWJOHtRtYUXouGFaLgvRIAy2NJpIRLJsaUm9VOSYXXOUKYtlEJkoDLJSKVkZBO/9kSpQbrcZzRrZvnKnpBGi+LPDcKNmPdrL/BFMvlR4WuPXObMUz+SzD/kd7vZ3h7q7x3iuuLCzjKbg8nbH9ajm7xY+oWxmVsZe0JUmpL1+gQDSAYhSWZ2/eVeWNwfokClyLFiNMzRz2wucR9ifZbJd1LUjZjN7vw9L6wmsS4kl6REbUG7H5MqdZeUROVojmcQhvbfWd9BFP10nePbc/y6UmFwYkyeHPKOtZiPb77Ed7+vsnxjbKSPdSFpswXNFlH9MS4MSkzLAQVx+8enCC7tLJLfKhB1ukb6WBdywOOf7vDht++gBCAOh0h1t4fs1KDexMRZ44yQ9Oo1wqvX7jquwIiIA6xfVF3DC9HwQjS8EA0vRMML0RD+ZQj/x48QDS9EwwvR8EI0vBANL0TjX8E5BcMcUxKSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(numbers_tensors['one'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6742, 28, 28])"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_numbers = {}\n",
    "for key, val in numbers_tensors.items():\n",
    "    stacked_numbers[key] = torch.stack(numbers_tensors[key]).float()/255\n",
    "stacked_numbers['one'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.35it/s]\n"
     ]
    }
   ],
   "source": [
    "valid_numbers = {}\n",
    "for i in tqdm((path/'testing').ls().sorted()):\n",
    "    num = str(i)[-1]\n",
    "    for n in num:\n",
    "        val = p.number_to_words(n)\n",
    "        valid_numbers[val] = (path/'testing/{}'.format(n)).ls().sorted()\n",
    "        valid_numbers[val] = torch.stack([tensor(Image.open(o)) for o in numbers[val]]).float()/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6742, 28, 28])"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_numbers['one'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.cat([val for key, val in stacked_numbers.items()]).view(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0,  ..., 0, 0, 0],\n",
       "        [1, 0, 0,  ..., 0, 0, 0],\n",
       "        [1, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 1],\n",
       "        [0, 0, 0,  ..., 0, 0, 1],\n",
       "        [0, 0, 0,  ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = tensor([[1,0,0,0,0,0,0,0,0,0] for i in range(len(stacked_numbers['zero']))]\n",
    "                + [[0,1,0,0,0,0,0,0,0,0] for i in range(len(stacked_numbers['one']))]\n",
    "                + [[0,0,1,0,0,0,0,0,0,0] for i in range(len(stacked_numbers['two']))]\n",
    "                + [[0,0,0,1,0,0,0,0,0,0] for i in range(len(stacked_numbers['three']))]\n",
    "                + [[0,0,0,0,1,0,0,0,0,0] for i in range(len(stacked_numbers['four']))]\n",
    "                + [[0,0,0,0,0,1,0,0,0,0] for i in range(len(stacked_numbers['five']))]\n",
    "                + [[0,0,0,0,0,0,1,0,0,0] for i in range(len(stacked_numbers['six']))]\n",
    "                + [[0,0,0,0,0,0,0,1,0,0] for i in range(len(stacked_numbers['seven']))]\n",
    "                + [[0,0,0,0,0,0,0,0,1,0] for i in range(len(stacked_numbers['eight']))]\n",
    "                + [[0,0,0,0,0,0,0,0,0,1] for i in range(len(stacked_numbers['nine']))])\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 784]), torch.Size([60000, 10]))"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = list(zip(train_x,train_y))\n",
    "x,y = dset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x = torch.cat([val for key,val in valid_numbers.items()]).view(-1,28*28)\n",
    "valid_y = tensor([[1,0,0,0,0,0,0,0,0,0] for i in range(len(valid_numbers['zero']))]\n",
    "                + [[0,1,0,0,0,0,0,0,0,0] for i in range(len(valid_numbers['one']))]\n",
    "                + [[0,0,1,0,0,0,0,0,0,0] for i in range(len(valid_numbers['two']))]\n",
    "                + [[0,0,0,1,0,0,0,0,0,0] for i in range(len(valid_numbers['three']))]\n",
    "                + [[0,0,0,0,1,0,0,0,0,0] for i in range(len(valid_numbers['four']))]\n",
    "                + [[0,0,0,0,0,1,0,0,0,0] for i in range(len(valid_numbers['five']))]\n",
    "                + [[0,0,0,0,0,0,1,0,0,0] for i in range(len(valid_numbers['six']))]\n",
    "                + [[0,0,0,0,0,0,0,1,0,0] for i in range(len(valid_numbers['seven']))]\n",
    "                + [[0,0,0,0,0,0,0,0,1,0] for i in range(len(valid_numbers['eight']))]\n",
    "                + [[0,0,0,0,0,0,0,0,0,1] for i in range(len(valid_numbers['nine']))])\n",
    "valid_dset = list(zip(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beginnning to define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = init_params((28*28,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = init_params(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.4896e+00,  9.6371e-01,  1.7793e-01,  ...,  5.2559e+00,\n",
       "          5.3317e+00,  1.4255e+01],\n",
       "        [ 1.5651e+01,  9.8830e-01,  8.4566e+00,  ...,  1.5454e+01,\n",
       "         -1.0391e-02,  2.3930e+01],\n",
       "        [ 1.1857e+01, -4.0593e+00,  1.8369e+01,  ...,  9.4074e+00,\n",
       "          5.4634e+00,  1.8201e+01],\n",
       "        ...,\n",
       "        [ 1.1146e+01, -1.1312e+01, -5.1409e+00,  ...,  1.4969e+01,\n",
       "         -2.8416e+00,  1.3877e+01],\n",
       "        [ 3.0697e+00, -8.8500e+00,  1.1295e+01,  ..., -8.0502e+00,\n",
       "          8.8821e+00,  8.6182e+00],\n",
       "        [ 1.4896e+01, -1.6350e+01,  1.6437e+00,  ...,  1.1326e+01,\n",
       "         -3.0540e+00,  7.3427e+00]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linear1(xb): return xb@weights + bias\n",
    "preds = linear1(train_x)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(predictions, targets):\n",
    "    #predictions = predictions.sigmoid()\n",
    "    predictions = predictions.softmax(dim=1)\n",
    "    target = torch.argmax(targets,1)\n",
    "    #return torch.where(targets==1, 1-predictions, predictions).mean()\n",
    "    return nn.CrossEntropyLoss()(predictions,target)\n",
    "    #loss = -(targets * predictions.log()).sum() / len(predictions)\n",
    "    #return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3512, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_loss(preds,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 784]), torch.Size([256, 10]))"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(dset, batch_size=256)\n",
    "valid_dl = DataLoader(valid_dset, batch_size=256)\n",
    "xb,yb = first(dl)\n",
    "xb.shape,yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing loss on small batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 784])"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = train_x[:4]\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = linear1(batch)\n",
    "#preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2625, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = mnist_loss(preds,train_y[:4])\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2500)"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_accuracy(linear1(batch), train_y[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1219"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_epoch(linear1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining functions to implement model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad(xb,yb, model):\n",
    "    preds = model(xb)\n",
    "    loss = mnist_loss(preds,yb)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, lr, params):\n",
    "    for xb,yb in dl:\n",
    "        calc_grad(xb,yb, model)\n",
    "        for p in params:\n",
    "            p.data -= p.grad*lr\n",
    "            p.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.softmax(dim=1)\n",
    "    predVal, predMax = torch.max(preds.data,1)\n",
    "    tarVal, tarMax = torch.max(yb,1)\n",
    "    correct = predMax == tarMax\n",
    "    return correct.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "params = weights,bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1027 0.103 0.1032 0.1034 0.1035 0.1038 0.104 0.1042 0.1044 0.1046 0.1048 0.1051 0.1053 0.1055 0.1057 0.1059 0.1061 0.1062 0.1065 0.1069 0.1072 0.1074 0.1077 0.1079 0.1081 0.1083 0.1085 0.1089 0.1092 0.1093 0.1095 0.1098 0.1101 0.1103 0.1107 0.1109 0.1112 0.1114 0.1116 0.1118 "
     ]
    }
   ],
   "source": [
    "for i in range(40):\n",
    "    train_epoch(linear1, lr, params)\n",
    "    print(validate_epoch(linear1), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
